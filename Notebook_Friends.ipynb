{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNjYVrVq9w3oaXA9GCVjFMt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# mounting GoogleDrive for Colab\n","try:\n"," from google.colab import drive\n"," drive.mount('/content/gdrive', force_remount=True)\n"," FOLDERNAME = 'Friends_Generator'\n"," %cd /content/gdrive/My\\ Drive/$FOLDERNAME\n","except ImportError:\n"," pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"caGxelmn8EZV","executionInfo":{"status":"ok","timestamp":1685276552768,"user_tz":-120,"elapsed":22202,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}},"outputId":"84ef7288-dfd8-4fae-9fb0-8d3031b303b3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content/gdrive/My Drive/Friends_Generator\n"]}]},{"cell_type":"markdown","source":["#Scraping Raw Data"],"metadata":{"id":"45N-CTCWdu2G"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1V9U5HiOvvxg"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup"]},{"cell_type":"code","source":["#Run for each season (1 to 8 usable) [manually combining all of them (for quality control)]\n","season = 1            #To change\n","script = ''\n","for i in range(1,25):\n","  episode = str(season) + '0'*(i<10) + str(i) \n","  url = f'https://www.oocities.org/friends_greatestsitcom4/script/{episode}.htm'\n","\n","  response = requests.get(url, verify=False)\n","  soup = BeautifulSoup(response.text, 'html.parser')\n","  script += soup.get_text()\n","\n","with open(f'script_{season}.txt', 'w') as file:\n","  file.write(script)"],"metadata":{"id":"Y-IB6h4seEiE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Cleaning Data"],"metadata":{"id":"NFCImKEZeqrO"}},{"cell_type":"code","source":["with open('friends_script.txt', 'r') as file:\n","  script = file.read()"],"metadata":{"id":"kTjmIighTNfb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Names of locutor are inconsistent\n","#line breaking is inconsistent\n","#quotation marks inconsistent\n","\n","names = {'Rachel:' : 'RACHEL:',\n","        'Monica:' : 'MONICA:',\n","        'Phoebe:' : 'PHOEBA:',\n","        'Joey:' : 'JOEY:',\n","        'Chandler:' : 'CHANDLER:',\n","        'Ross:' : 'ROSS:',\n","        'RACH:' : 'RACHEL:',\n","        'MNCA:' : 'MONICA:',\n","        'PHOE:' : 'PHOEBE:',\n","        'CHAN:' : 'CHANDLER',\n","        'Janice:' : 'JANICE:',\n","        'Pete:' : 'PETE:',\n","        'All:' : 'ALL:',\n","        'The Girls:' : 'THE GIRLS:',\n","        'Kathy:' : 'KATHY:',\n","        'Emily:' : 'EMILY:',\n","        'Joshua:' : 'JOSHUA:',\n","        'Elizabeth:' : 'ELIZABETH:',\n","        'Mona:' : 'MONA:'\n","}\n","\n","quotes = {'‘' : '\"',\n","          '’' : '\"',\n","          '“' : '\"',\n","          '”' : '\"'    \n","}\n","\n","script = script.replace('\\n\\n', '\\n')\n","script = script.replace('\\t', ' ')\n","script = script.replace('�', '\\'')\n","for name, replacement in names.items():\n","  script = script.replace(name, replacement)\n","for quote, replacement in quotes.items():\n","  script = script.replace(quote, replacement)"],"metadata":{"id":"mos5vsrZUb-t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('friends_script.txt', 'w') as file:\n","  file.write(script)"],"metadata":{"id":"w3TrV3Q4VtLg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#The Model"],"metadata":{"id":"TslGelxxfOGV"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from tqdm import tqdm"],"metadata":{"id":"SnZMN4eLwEsN","executionInfo":{"status":"ok","timestamp":1685276557308,"user_tz":-120,"elapsed":4543,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["batch_size = 64\n","block_size = 300 #max context size\n","max_iters = 20000 #training loop steps\n","eval_interval = 500 #every steps we eval loss\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","eval_iters = 200 #number of random batches used to eval loss\n","n_embd = 32 #number of embedding dimension\n","n_heads = 4 #number of attention heads\n","n_blocks = 6 #number of unit blocks in transformer\n","dropout = .1 #dropout in dropout layers in training"],"metadata":{"id":"Oic3-nhq8IAw","executionInfo":{"status":"ok","timestamp":1685276557308,"user_tz":-120,"elapsed":4,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["with open('friends_script.txt', 'r') as file:\n","  text = file.read()"],"metadata":{"id":"JsVr-SAbVu-u","executionInfo":{"status":"ok","timestamp":1685276558132,"user_tz":-120,"elapsed":827,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#unique characters\n","chars = sorted(list(set(text)))\n","vocab_size = len(chars)"],"metadata":{"id":"jh3E4ZfVgRUV","executionInfo":{"status":"ok","timestamp":1685276558133,"user_tz":-120,"elapsed":5,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#mapping functions char to int (basic tokenizer)\n","stoi = {ch:i for i, ch in enumerate(chars)}\n","itos = {i:ch for i, ch in enumerate(chars)}\n","\n","encode = lambda s: [stoi[c] for c in s]\n","decode = lambda l: ''.join([itos[i] for i in l])"],"metadata":{"id":"z8wGbecwtHLa","executionInfo":{"status":"ok","timestamp":1685276558133,"user_tz":-120,"elapsed":4,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#data loading and train/val split\n","data = torch.tensor(encode(text), dtype=torch.long)\n","train_data = data[:int(0.9*len(data))]\n","val_data = data[int(0.9*len(data)):]"],"metadata":{"id":"PdOrRCTwvZR_","executionInfo":{"status":"ok","timestamp":1685276558546,"user_tz":-120,"elapsed":416,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def get_batch(split):\n","  #generate a random batch of data with input x and targets y\n","  data = train_data if split == 'train' else val_data\n","  ix = torch.randint(len(data) - block_size, (batch_size,))\n","  x = torch.stack([data[i:i+block_size] for i in ix])\n","  y = torch.stack([data[i+1:i+1+block_size] for i in ix])\n","  return x.to(device), y.to(device)"],"metadata":{"id":"MJE4SCGNw7WK","executionInfo":{"status":"ok","timestamp":1685276558546,"user_tz":-120,"elapsed":7,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#function to give steady estimation of loss\n","@torch.no_grad()\n","def estimate_loss(model):\n","  out = {}\n","  model.eval()\n","  for split in ['train', 'val']:\n","    losses = torch.zeros(eval_iters)\n","    for k in range(eval_iters):\n","      X, Y = get_batch(split)\n","      logits, loss = model(X, Y)\n","      losses[k] = loss.item()\n","    out[split] = losses.mean()\n","  model.train()\n","  return out"],"metadata":{"id":"pqP_agJ6-U-O","executionInfo":{"status":"ok","timestamp":1685276558547,"user_tz":-120,"elapsed":8,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class GPTLanguageModel(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.token_embedding_table = nn.Embedding(vocab_size, n_embd)   #embedding token\n","    self.position_embedding_table = nn.Embedding(block_size, n_embd) #create an embedding for position idx too\n","    self.transformer = nn.Sequential(*[Block(n_embd=n_embd, n_heads=n_heads) for _ in range(n_blocks)])\n","    self.layernorm_final = nn.LayerNorm(n_embd)\n","    self.language_modeling_head = nn.Linear(n_embd, vocab_size)     #linear layer\n","\n","  def forward(self, idx, targets=None):\n","    #idx and targets are (B,T)\n","    B, T = idx.shape\n","    tok_emb = self.token_embedding_table(idx)  #(B,T,C) doesn't give directly logits as we go through intermediate dimension of embedding\n","    pos_emb = self.position_embedding_table(torch.arange(T, device=device)) #(T,C)\n","    x = tok_emb + pos_emb   #(B,T,C) pos_emb are broadcasted along B dim\n","    x = self.transformer(x) #(B,T,C)\n","    x = self.layernorm_final(x) #(B,T,C)\n","    logits = self.language_modeling_head(x)    #(B,T,vocab_size)\n","\n","    if targets != None:\n","      B, T, C = logits.shape\n","      logits = logits.view(B*T,C) #(B*T,C)\n","      targets = targets.view(B*T)\n","      loss = F.cross_entropy(logits, targets)\n","      return logits, loss\n","    return logits, None\n","  \n","  def generate(self, idx, max_new_tokens):      #Used to create new text (not in training phase)\n","    #idx is (B,T)\n","    for _ in range(max_new_tokens):\n","      idx_cond = idx[:, -block_size:]  #have to crop to the last block size of given context\n","      logits, loss = self(idx_cond) #get predictions\n","      logits = logits[:, -1, :] #focus on last time step (B,C) (history not used yet)\n","      probs = F.softmax(logits, dim=-1) #get probas (B,C)\n","      idx_next = torch.multinomial(probs, num_samples=1) #sample from the probs distribution (B,1)\n","      idx = torch.cat((idx, idx_next), dim=1) #append new index to running sequence (B,T+1)\n","    return idx"],"metadata":{"id":"lrSPq41VxOqj","executionInfo":{"status":"ok","timestamp":1685276558547,"user_tz":-120,"elapsed":7,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["class Head(nn.Module):\n","  #One head of attention mechanism\n","  def __init__(self, head_size):\n","    super().__init__()\n","    self.key = nn.Linear(n_embd, head_size, bias=False)\n","    self.query = nn.Linear(n_embd, head_size, bias=False)\n","    self.value = nn.Linear(n_embd, head_size, bias=False)\n","    self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size))) #create the 'tril' variable from buffer as not a parameter of the model (lower triangular matrix of ones - will be useful for masking)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, x):\n","    B,T,C = x.shape\n","    k = self.key(x) #(B,T,C)\n","    q = self.query(x) #(B,T,C)\n","    v = self.value(x) #(B,T,C)\n","\n","    #compute the weights to be used in attention \n","    weights = q @ k.transpose(-2,-1) * torch.sqrt(torch.tensor(C)).item() #(B,T,C) @ (B,C,T) = (B,T,T) (also the paper introduces a 1/sqrt(C) factor to avoid (one-hot)-like weights after softmax)\n","    weights = weights.masked_fill(self.tril[:T,:T] == 0, float('-inf')) #masking upper triangular values as we can't communicate with future (B,T,T)\n","    weights = F.softmax(weights, dim=-1) #softmax to normalize (as probas) (B,T,T)\n","    weights = self.dropout(weights)\n","\n","    #finnaly aggregate the values using these weights\n","    out = weights @ v #(B,T,T) @ (B,T,C) = (B,T,C)\n","    return out"],"metadata":{"id":"M0B8jqiAlMu2","executionInfo":{"status":"ok","timestamp":1685276558547,"user_tz":-120,"elapsed":6,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class MultiHead(nn.Module):\n","#Multiple head model\n","  def __init__(self, num_heads, head_size):\n","    super().__init__()\n","    self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","    self.projection = nn.Linear(n_embd, n_embd)   #need to project the list back into shape for skip connection (+ with original x)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, x):\n","    out = torch.cat([h(x) for h in self.heads], dim=-1)\n","    out = self.projection(out)\n","    #out = self.dropout(x)\n","    return out"],"metadata":{"id":"DFs4YamDBk1a","executionInfo":{"status":"ok","timestamp":1685276558548,"user_tz":-120,"elapsed":7,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class FeedForward(nn.Module):\n","#Final part of decoder-only-transformer block\n","  def __init__(self, n_embd):\n","    super().__init__()\n","    self.net = nn.Sequential(\n","        nn.Linear(n_embd, 4*n_embd),    #factor 4 comes from paper\n","        nn.ReLU(),\n","        nn.Linear(4*n_embd, n_embd),  #here to project the list back into shape for skip connection (+ with original x)\n","        nn.Dropout(dropout),\n","    )\n","\n","  def forward(self, x):\n","    return self.net(x)"],"metadata":{"id":"A_SnGPkTE5i2","executionInfo":{"status":"ok","timestamp":1685276558548,"user_tz":-120,"elapsed":7,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class Block(nn.Module):\n","#(decoder only)-Transformer unit block\n","  def __init__(self, n_embd, n_heads):\n","    super().__init__()\n","    head_size = n_embd // n_heads\n","    self.multi_attention = MultiHead(n_heads, head_size)\n","    self.feedforward = FeedForward(n_embd)\n","    self.layernorm1 = nn.LayerNorm(n_embd)\n","    self.layernorm2 = nn.LayerNorm(n_embd)\n","\n","  def forward(self, x):\n","    x = x + self.multi_attention(self.layernorm1(x))  #with skip connection (layer normalization is applied before skip connection unlike in the paper)\n","    x = x + self.feedforward(self.layernorm2(x))  #with skip connection (layer normalization is applied before skip connection unlike in the paper)\n","    return x"],"metadata":{"id":"MxfQk9jJHNLo","executionInfo":{"status":"ok","timestamp":1685276558548,"user_tz":-120,"elapsed":6,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["#Training"],"metadata":{"id":"nGUNcBCw2xdN"}},{"cell_type":"code","source":["#Model\n","model = GPTLanguageModel().to(device)"],"metadata":{"id":"PmmH-Mpy_eW4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["learning_rate=1e-2\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","#training loop\n","for iter in tqdm(range(max_iters)):\n","  #update learning rate\n","  if iter % 5000 == 0 and iter > 0:\n","    learning_rate /= 10\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","  #evaluate loss\n","  if iter % eval_interval == 0:\n","    losses = estimate_loss(model)\n","    print(f\"iter {iter}: train_loss={losses['train']:.3f}, val_loss={losses['val']:.3f}\")\n","\n","  xb, yb = get_batch('train')\n","  logits, loss = model(xb, yb)\n","  optimizer.zero_grad(set_to_none=True)\n","  loss.backward()\n","  optimizer.step()\n","\n","final_loss = estimate_loss(model)['val']"],"metadata":{"id":"UCTJ1qDA6ouv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#save model\n","torch.save(model, f'model_{final_loss:.2f}.pth')"],"metadata":{"id":"yVx7HO6gk4U4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(sum(p.numel() for p in model.parameters())/1e3, 'k parameters')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xs4XM-25lwUW","executionInfo":{"status":"ok","timestamp":1685269976642,"user_tz":-120,"elapsed":250,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}},"outputId":"a024d903-05b8-4859-beb7-ae2b36c13c3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["91.487 k parameters\n"]}]},{"cell_type":"markdown","source":["#Loading and Dumping model in pickel"],"metadata":{"id":"sG52I7_8T6U2"}},{"cell_type":"code","source":["#Loading and evaluating model\n","weights_file = 'model_1.33.pth'\n","\n","model = torch.load(weights_file, map_location=device)\n","model.eval()\n","\n","estimate_loss(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2pedRcV_20jm","executionInfo":{"status":"ok","timestamp":1685276594404,"user_tz":-120,"elapsed":28994,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}},"outputId":"2670bda2-7747-4ead-e1d1-5b7a1153e91e"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'train': tensor(1.3097), 'val': tensor(1.3312)}"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["import pickle\n","\n","pickle_model = {\n","    'model':model,\n","    }\n","\n","with open('model_pickel.pkl', 'wb') as file:\n","  pickle.dump(pickle_model, file)\n"],"metadata":{"id":"0ZAphZsnT_ku","executionInfo":{"status":"ok","timestamp":1685276892407,"user_tz":-120,"elapsed":3,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["#Tests"],"metadata":{"id":"Usv-udZ63TYs"}},{"cell_type":"code","source":["context = 'CHANDLER: Stop messing around Joey!\\n'\n","input = torch.tensor(encode(context), dtype=torch.long).view(1,len(context)).to(device)"],"metadata":{"id":"BpX2WFme7OCJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(decode(model.generate(idx = input, max_new_tokens=1000)[0].tolist()))"],"metadata":{"id":"Nz7OAogI9nYA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685269898057,"user_tz":-120,"elapsed":13410,"user":{"displayName":"adrien sade","userId":"09079267221407323456"}},"outputId":"50100670-e099-4f76-b610-ae9b92f26ddf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CHANDLER: Stop messing around Joey!\n","Hey.\n","JOEY: Oh my!\n","JOEY: No-no, you're gonna wants minutes Ursival\n","to room.\n","CHANDLER: We tell take the gigleact it, I got that. So I'm from him lod bar-\n","Ben: Oh we don't got Ross on, why don\"t you what\"s shone. I\"m that? (She was over gass in off allief?\n","[Monica sfids.\"\n","Joey.NER: He doesn'te doing much ended\n","you know, that Ross\"s old much guys to at And! (To Joey enough.)\n","RACHEL: Thank we six about at the \n","guy.\n","MONICA: What you have a hoor?\n","[Scene: Central Perk, Chandler are catce onoment to Sweas.\n","ROSS: Oh, closh. Ross's puting coffect bunies?)\n","ROSS: Yeah, it up on look to sreame anything to of the picting is that didno her sulibly lown\"t asrwall prolm up! My Thank it!\n","CHANDLER: Shaceles me. I donkstad! I\"m 1400 up.\n","Monica) Mof ofezelow I\"m up.\n","JOEY: What about then with be you would gonna say the 17; deack.\n","JOEY: No! (Some faceming lask.) \n","RACL: It wanna go to molle, perseuler, hads By.\n","We\"ll: (spils.)\n","Ross, Russ, even bags. This right sorry.JUNICA: Oh! That bad I\"ll go my to hair def\n"]}]}]}